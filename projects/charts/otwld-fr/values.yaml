#
# IMPORTANT NOTE
#
# This chart inherits from our common library chart. You can check the default values/options here:
# https://github.com/k8s-at-home/library-charts/tree/main/charts/stable/common/values.yaml
#

image:
  # -- image repository
  repository: docker.outworld.fr/ecosystem/otwld-fr
  # -- image tag
  tag: "latest"
  # -- image pull policy
  pullPolicy: Always

imagePullSecrets:
  - name: dockerconfig-secret

ingressroute:
  enabled: true
  annotations: { }
  # kubernetes.io/ingress.class: nginx
  # kubernetes.io/tls-acme: "true"
  tls: true
  routes:
    - host: new.outworld.fr
      priority: 10
      services:
        - passHostHeader: true
          name: ecosystem-otwld-fr
          port: 80
backup:
  enabled: false
#  schedule:
#    enabled: true
#    annotations: { }
#    # Cron expression defining when to run the Backup
#    cron: '0 04 * * *'
#    # Array of namespaces to include in the scheduled backup. If unspecified, all namespaces are included.
#    # Optional.
#    includedNamespaces:
#      - ecosystem
#    # Array of resources to include in the scheduled backup. Resources may be shortcuts (for example 'po' for 'pods')
#    # or fully-qualified. If unspecified, all resources are included. Optional.
#    includedResources:
#      - '*'
#    # Whether or not to include cluster-scoped resources. Valid values are true, false, and
#    # null/unset. If true, all cluster-scoped resources are included (subject to included/excluded
#    # resources and the label selector). If false, no cluster-scoped resources are included. If unset,
#    # all cluster-scoped resources are included if and only if all namespaces are included and there are
#    # no excluded namespaces. Otherwise, if there is at least one namespace specified in either
#    # includedNamespaces or excludedNamespaces, then the only cluster-scoped resources that are backed
#    # up are those associated with namespace-scoped resources included in the scheduled backup. For example, if a
#    # PersistentVolumeClaim is included in the backup, its associated PersistentVolume (which is
#    # cluster-scoped) would also be backed up.
#    includeClusterResources: true
#    # Whether or not to snapshot volumes. This only applies to PersistentVolumes for Azure, GCE, and
#    # AWS. Valid values are true, false, and null/unset. If unset, Velero performs snapshots as long as
#    # a persistent volume provider is configured for Velero.
#    snapshotVolumes: true
#    # Where to store the tarball and logs.
#    storageLocation: backups-short-ttl
#    # The list of locations in which to store volume snapshots created for backups under this schedule.
#    volumeSnapshotLocations:
#      - ovhcloud
#    # The amount of time before backups created on this schedule are eligible for garbage collection. If not specified,
#    # a default value of 30 days will be used. The default can be configured on the velero server
#    # by passing the flag --default-backup-ttl.
#    ttl: 48h0m0s

# -- environment variables. See [image docs](https://jellyfin.org/docs/general/administration/configuration.html) for more details.
# @default -- See below
env:
  # -- Set the container timezone
  TZ: UTC

# -- Specify any additional containers here as dictionary items. Each additional container should have its own key.
# Helm templates can be used.
additionalContainers: {}

# -- Configures service settings for the chart.
# @default -- See values.yaml
service:
  main:
    enabled: true
    ports:
      http:
        port: 80

controller:
  # -- enable the controller.
  enabled: true
  replicas: 1

ingress:
  # -- Enable and configure ingress settings for the chart under this key.
  # @default -- See values.yaml
  main:
    enabled: false

# -- Configure persistence settings for the chart under this key.
# @default -- See values.yaml
persistence:
  config:
    enabled: false
    type: pvc
    accessMode: ReadWriteOnce
    storageClass: longhorn
    size: 5Gi

  # Cache does NOT contain temporary transcoding data.
  cache:
    enabled: false
    mountPath: /cache

  media:
    enabled: true
    mountPath: /media
    type: pvc
    accessMode: ReadWriteOnce
    storageClass: longhorn
    size: 20Gi

# -- Configure the Security Context for the Pod
podSecurityContext: {}
#   runAsUser: 568
#   runAsGroup: 568
#   fsGroup: 568
#   # Hardware acceleration using an Intel iGPU w/ QuickSync
#   # These IDs below should be matched to your `video` and `render` group on the host
#   # To obtain those IDs run the following grep statement on the host:
#   # $ cat /etc/group | grep "video\|render"
#   # video:x:44:
#   # render:x:109:
#   supplementalGroups:
#   - 44
#   - 109

# resources:
#   requests:
#     # Hardware acceleration using an Intel iGPU w/ QuickSync and
#     # using intel-gpu-plugin (https://github.com/intel/intel-device-plugins-for-kubernetes)
#     gpu.intel.com/i915: 1
#     cpu: 200m
#     memory: 256Mi
#   limits:
#     # Hardware acceleration using an Intel iGPU w/ QuickSync and
#     # using intel-gpu-plugin (https://github.com/intel/intel-device-plugins-for-kubernetes)
#     gpu.intel.com/i915: 1
#     memory: 4096Mi
